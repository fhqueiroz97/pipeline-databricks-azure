# Databricks notebook source
# MAGIC %md
# MAGIC # Silver Layer - Transforma√ß√£o e Limpeza de Dados
# MAGIC
# MAGIC **Objetivo**: Limpar, transformar e estruturar dados da Bronze Layer
# MAGIC
# MAGIC **Caracter√≠sticas da Silver Layer**:
# MAGIC - Dados limpos e validados
# MAGIC - Transforma√ß√µes de neg√≥cio aplicadas
# MAGIC - Estrutura otimizada para an√°lise
# MAGIC - Qualidade de dados garantida

# COMMAND ----------

# MAGIC %md
# MAGIC ## 1. Configura√ß√µes e Imports

# COMMAND ----------

from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
from datetime import datetime
import uuid

# Configura√ß√µes do ambiente
workspace_path = "/Workspace/Repos/senaipr31@fiap.com.br/pipeline-databricks-azure/src"
bronze_path = f"{workspace_path}/data/bronze"
silver_path = f"{workspace_path}/data/silver"

print(f"Bronze Layer Path: {bronze_path}")
print(f"Silver Layer Path: {silver_path}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 2. Leitura dos Dados da Bronze Layer

# COMMAND ----------

# Configura√ß√µes de otimiza√ß√£o
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")

try:
    # Lendo dados da Bronze
    df_bronze = spark.read.format("delta").load(f"{bronze_path}/vendas")
    
    print(f"‚úÖ Dados carregados da Bronze Layer: {df_bronze.count()} registros")
    
    # Mostrando estrutura atual
    print("\nüìã Estrutura dos dados da Bronze:")
    df_bronze.printSchema()
    
    # Amostra dos dados
    display(df_bronze.limit(5))
    
except Exception as e:
    print(f"‚ùå Erro ao carregar dados da Bronze: {str(e)}")
    print("Execute primeiro o notebook 01_Bronze_Layer_Ingestion")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 3. Fun√ß√µes de Transforma√ß√£o e Limpeza

# COMMAND ----------

def aplicar_limpeza_dados(df):
    """
    Aplica limpeza b√°sica nos dados
    """
    df_limpo = df.filter(col("id_venda").isNotNull()) \
                 .filter(col("valor") > 0) \
                 .filter(col("cliente").isNotNull()) \
                 .filter(col("bronze_is_deleted") == False)
    
    return df_limpo

def aplicar_transformacoes_negocio(df):
    """
    Aplica transforma√ß√µes de neg√≥cio espec√≠ficas
    """
    df_transformado = df.withColumn("data_venda_date", to_date(col("data_venda"), "yyyy-MM-dd")) \
                        .withColumn("ano_venda", year(col("data_venda_date"))) \
                        .withColumn("mes_venda", month(col("data_venda_date"))) \
                        .withColumn("valor_com_desconto", 
                                  when(col("valor") > 200, col("valor") * 0.9)
                                  .otherwise(col("valor"))) \
                        .withColumn("categoria_valor", 
                                  when(col("valor") <= 100, "Baixo")
                                  .when(col("valor") <= 200, "M√©dio")
                                  .otherwise("Alto")) \
                        .withColumn("cliente_normalizado", 
                                  initcap(trim(col("cliente"))))
    
    return df_transformado

def adicionar_metadados_silver(df):
    """
    Adiciona metadados de controle para Silver Layer
    """
    df_silver = df.withColumn("silver_load_timestamp", current_timestamp()) \
                  .withColumn("silver_load_id", lit(str(uuid.uuid4()))) \
                  .withColumn("silver_quality_score", lit(100))  # Score de qualidade
    
    return df_silver

# COMMAND ----------

# MAGIC %md
# MAGIC ## 4. Aplica√ß√£o das Transforma√ß√µes

# COMMAND ----------

# Aplicando pipeline de transforma√ß√£o
print("üîÑ Iniciando transforma√ß√µes...")

# Passo 1: Limpeza
df_limpo = aplicar_limpeza_dados(df_bronze)
print(f"Ap√≥s limpeza: {df_limpo.count()} registros")

# Passo 2: Transforma√ß√µes de neg√≥cio
df_transformado = aplicar_transformacoes_negocio(df_limpo)
print("‚úÖ Transforma√ß√µes de neg√≥cio aplicadas")

# Passo 3: Sele√ß√£o de colunas para Silver
colunas_silver = [
    "id_venda",
    "cliente_normalizado",
    "produto", 
    "valor",
    "valor_com_desconto",
    "categoria_valor",
    "data_venda_date",
    "ano_venda",
    "mes_venda",
    "estado",
    "bronze_load_id"  # Mant√©m rastreabilidade
]

df_silver_prep = df_transformado.select(*colunas_silver)

# Passo 4: Adi√ß√£o de metadados Silver
df_silver = adicionar_metadados_silver(df_silver_prep)

print("üéØ Pipeline de transforma√ß√£o conclu√≠do!")
display(df_silver.limit(5))

# COMMAND ----------

# MAGIC %md
# MAGIC ## 5. Valida√ß√£o de Qualidade dos Dados

# COMMAND ----------

def validar_qualidade_silver(df):
    """
    Executa valida√ß√µes de qualidade na Silver Layer
    """
    print("üîç VALIDA√á√ÉO DE QUALIDADE - SILVER LAYER")
    print("=" * 50)
    
    # Contagem total
    total_registros = df.count()
    print(f"üìä Total de registros: {total_registros}")
    
    # Verificar valores nulos em campos cr√≠ticos
    campos_criticos = ["id_venda", "cliente_normalizado", "valor", "data_venda_date"]
    
    for campo in campos_criticos:
        nulos = df.filter(col(campo).isNull()).count()
        if nulos > 0:
            print(f"‚ö†Ô∏è  Campo '{campo}' possui {nulos} valores nulos")
        else:
            print(f"‚úÖ Campo '{campo}' sem valores nulos")
    
    # Verificar duplicatas
    duplicatas = df.count() - df.dropDuplicates(["id_venda"]).count()
    if duplicatas > 0:
        print(f"‚ö†Ô∏è  Encontradas {duplicatas} duplicatas")
    else:
        print("‚úÖ Sem duplicatas encontradas")
    
    # Estat√≠sticas de valores
    print(f"\nüí∞ Valor m√©dio: R$ {df.agg(avg('valor')).collect()[0][0]:.2f}")
    print(f"üí∞ Valor m√°ximo: R$ {df.agg(max('valor')).collect()[0][0]:.2f}")
    
    # Distribui√ß√£o por categoria
    print("\nüìà Distribui√ß√£o por categoria de valor:")
    df.groupBy("categoria_valor").count().show()
    
    return total_registros > 0  # Retorna True se passou na valida√ß√£o b√°sica

# Executando valida√ß√£o
validacao_ok = validar_qualidade_silver(df_silver)

# COMMAND ----------

# MAGIC %md
# MAGIC ## 6. Salvamento na Silver Layer

# COMMAND ----------

if validacao_ok:
    try:
        # Salvando em formato Delta com otimiza√ß√µes
        df_silver.write \
            .format("delta") \
            .mode("overwrite") \
            .option("mergeSchema", "true") \
            .option("overwriteSchema", "true") \
            .partitionBy("ano_venda", "mes_venda") \
            .save(f"{silver_path}/vendas_transformadas")
        
        print("‚úÖ Dados salvos com sucesso na Silver Layer!")
        
        # Otimiza√ß√£o da tabela Delta
        spark.sql(f"OPTIMIZE delta.`{silver_path}/vendas_transformadas`")
        print("üöÄ Otimiza√ß√£o Delta aplicada!")
        
    except Exception as e:
        print(f"‚ùå Erro ao salvar na Silver Layer: {str(e)}")
else:
    print("‚ùå Valida√ß√£o falhou. Dados n√£o foram salvos na Silver Layer.")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 7. Cria√ß√£o de Views para An√°lise

# COMMAND ----------

# Criando view tempor√°ria para an√°lises
try:
    df_silver_final = spark.read.format("delta").load(f"{silver_path}/vendas_transformadas")
    df_silver_final.createOrReplaceTempView("vendas_silver")
    
    print("‚úÖ View 'vendas_silver' criada com sucesso!")
    
    # Exemplo de an√°lise usando SQL
    spark.sql("""
        SELECT 
            estado,
            categoria_valor,
            COUNT(*) as total_vendas,
            SUM(valor) as receita_total,
            AVG(valor) as ticket_medio
        FROM vendas_silver 
        GROUP BY estado, categoria_valor
        ORDER BY receita_total DESC
    """).show()
    
except Exception as e:
    print(f"Erro ao criar view: {str(e)}")

# COMMAND ----------

# MAGIC %md
# MAGIC ## 8. Monitoramento da Silver Layer

# COMMAND ----------

def monitorar_silver_layer():
    """
    Monitora m√©tricas da Silver Layer
    """
    try:
        df = spark.read.format("delta").load(f"{silver_path}/vendas_transformadas")
        
        print("=" * 60)
        print("üìä MONITORAMENTO SILVER LAYER")
        print("=" * 60)
        
        # M√©tricas gerais
        total_registros = df.count()
        receita_total = df.agg(sum("valor")).collect()[0][0]
        
        print(f"Total de registros processados: {total_registros}")
        print(f"Receita total: R$ {receita_total:,.2f}")
        print(f"√öltima atualiza√ß√£o: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # Top 3 estados por receita
        print("\nüèÜ Top 3 Estados por Receita:")
        df.groupBy("estado") \
          .agg(sum("valor").alias("receita")) \
          .orderBy(desc("receita")) \
          .limit(3) \
          .show()
        
        # Qualidade dos dados
        registros_qualidade = df.filter(col("silver_quality_score") >= 90).count()
        percentual_qualidade = (registros_qualidade / total_registros) * 100
        
        print(f"üìà Qualidade dos dados: {percentual_qualidade:.1f}%")
        
    except Exception as e:
        print(f"Erro no monitoramento: {str(e)}")

# Executando monitoramento
monitorar_silver_layer()

# COMMAND ----------

# MAGIC %md
# MAGIC ## 9. Resumo e Pr√≥ximos Passos
# MAGIC
# MAGIC ### ‚úÖ O que foi feito:
# MAGIC - Limpeza e valida√ß√£o de dados da Bronze Layer
# MAGIC - Aplica√ß√£o de transforma√ß√µes de neg√≥cio
# MAGIC - Cria√ß√£o de campos calculados e categoriza√ß√µes
# MAGIC - Valida√ß√£o de qualidade automatizada
# MAGIC - Otimiza√ß√£o com formato Delta e particionamento
# MAGIC
# MAGIC
# MAGIC ### üìã Boas Pr√°ticas Aplicadas:
# MAGIC - **Valida√ß√£o de qualidade**: Verifica√ß√µes autom√°ticas
# MAGIC - **Transforma√ß√µes modulares**: Fun√ß√µes reutiliz√°veis
# MAGIC - **Particionamento inteligente**: Por ano/m√™s para performance
# MAGIC - **Rastreabilidade**: Mant√©m liga√ß√£o com Bronze Layer
# MAGIC - **Otimiza√ß√£o Delta**: Para melhor performance de leitura
